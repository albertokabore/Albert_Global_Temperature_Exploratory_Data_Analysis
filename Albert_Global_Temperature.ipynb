{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dependencies \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from matplotlib) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from matplotlib) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from seaborn) (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alber\\albert_global_temperature_exploratory_data_analysis\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task Phases for EDA using Python: \n",
    "1. Data Preprocessing: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Load the Data: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv('Global_Temp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Data Inspection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                          Land-Ocean: Global Means\n",
      "Year Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec  J-D  D-N  DJF  MAM  JJA                       SON\n",
      "1880 -.20 -.26 -.09 -.17 -.10 -.22 -.21 -.11 -.16 -.23 -.23 -.19 -.18 ***  ***  -.12 -.18                     -.21\n",
      "1881 -.20 -.16 .02  .03  .06  -.19 .00  -.05 -.16 -.22 -.19 -.08 -.10 -.11 -.18 .04  -.08                     -.19\n",
      "1882 .15  .13  .04  -.17 -.14 -.23 -.17 -.08 -.15 -.24 -.17 -.37 -.12 -.09 .07  -.09 -.16                     -.19\n",
      "1883 -.30 -.37 -.13 -.19 -.18 -.08 -.08 -.15 -.23 -.12 -.24 -.12 -.18 -.20 -.35 -.17 -.10                     -.20\n"
     ]
    }
   ],
   "source": [
    "# Inspect first rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shape & data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 1)\n",
      "Land-Ocean: Global Means    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Clean the Data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the dataset with proper parsing to handle spacing issues\n",
    "df = pd.read_csv('Global_Temp.csv', skiprows=1)  # Skipping the first row as it might be incorrectly formatted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for easier access\n",
    "df.columns = [\"Year\", \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\",\n",
    "              \"J-D\", \"D-N\", \"DJF\", \"MAM\", \"JJA\", \"SON\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'Year' column is in integer format\n",
    "df[\"Year\"] = pd.to_numeric(df[\"Year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Convert all temperature anomaly columns to numeric, handling non-numeric values\n",
    "for col in df.columns[1:]:  # Excluding 'Year'\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145 entries, 0 to 144\n",
      "Data columns (total 19 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Year    145 non-null    Int64  \n",
      " 1   Jan     145 non-null    float64\n",
      " 2   Feb     145 non-null    float64\n",
      " 3   Mar     145 non-null    float64\n",
      " 4   Apr     145 non-null    float64\n",
      " 5   May     145 non-null    float64\n",
      " 6   Jun     145 non-null    float64\n",
      " 7   Jul     145 non-null    float64\n",
      " 8   Aug     145 non-null    float64\n",
      " 9   Sep     145 non-null    float64\n",
      " 10  Oct     145 non-null    float64\n",
      " 11  Nov     145 non-null    float64\n",
      " 12  Dec     145 non-null    float64\n",
      " 13  J-D     145 non-null    float64\n",
      " 14  D-N     145 non-null    float64\n",
      " 15  DJF     145 non-null    float64\n",
      " 16  MAM     145 non-null    float64\n",
      " 17  JJA     145 non-null    float64\n",
      " 18  SON     145 non-null    float64\n",
      "dtypes: Int64(1), float64(18)\n",
      "memory usage: 21.8 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Year    0\n",
       "Jan     0\n",
       "Feb     0\n",
       "Mar     0\n",
       "Apr     0\n",
       "May     0\n",
       "Jun     0\n",
       "Jul     0\n",
       "Aug     0\n",
       "Sep     0\n",
       "Oct     0\n",
       "Nov     0\n",
       "Dec     0\n",
       "J-D     0\n",
       "D-N     1\n",
       "DJF     1\n",
       "MAM     0\n",
       "JJA     0\n",
       "SON     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill missing values with the column mean\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Verify the data types and missing values after cleaning\n",
    "df_info = df.info()\n",
    "\n",
    "# Display missing values count\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145 entries, 0 to 144\n",
      "Data columns (total 19 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Year    145 non-null    Int64  \n",
      " 1   Jan     145 non-null    float64\n",
      " 2   Feb     145 non-null    float64\n",
      " 3   Mar     145 non-null    float64\n",
      " 4   Apr     145 non-null    float64\n",
      " 5   May     145 non-null    float64\n",
      " 6   Jun     145 non-null    float64\n",
      " 7   Jul     145 non-null    float64\n",
      " 8   Aug     145 non-null    float64\n",
      " 9   Sep     145 non-null    float64\n",
      " 10  Oct     145 non-null    float64\n",
      " 11  Nov     145 non-null    float64\n",
      " 12  Dec     145 non-null    float64\n",
      " 13  J-D     145 non-null    float64\n",
      " 14  D-N     145 non-null    float64\n",
      " 15  DJF     145 non-null    float64\n",
      " 16  MAM     145 non-null    float64\n",
      " 17  JJA     145 non-null    float64\n",
      " 18  SON     145 non-null    float64\n",
      "dtypes: Int64(1), float64(18)\n",
      "memory usage: 21.8 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    Year   Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov  \\\n",
       " 0  1880 -0.20 -0.26 -0.09 -0.17 -0.10 -0.22 -0.21 -0.11 -0.16 -0.23 -0.23   \n",
       " 1  1881 -0.20 -0.16  0.02  0.03  0.06 -0.19  0.00 -0.05 -0.16 -0.22 -0.19   \n",
       " 2  1882  0.15  0.13  0.04 -0.17 -0.14 -0.23 -0.17 -0.08 -0.15 -0.24 -0.17   \n",
       " 3  1883 -0.30 -0.37 -0.13 -0.19 -0.18 -0.08 -0.08 -0.15 -0.23 -0.12 -0.24   \n",
       " 4  1884 -0.13 -0.09 -0.37 -0.41 -0.34 -0.35 -0.31 -0.28 -0.28 -0.25 -0.34   \n",
       " \n",
       "     Dec   J-D       D-N       DJF   MAM   JJA   SON  \n",
       " 0 -0.19 -0.18  0.074444  0.068889 -0.12 -0.18 -0.21  \n",
       " 1 -0.08 -0.10 -0.110000 -0.180000  0.04 -0.08 -0.19  \n",
       " 2 -0.37 -0.12 -0.090000  0.070000 -0.09 -0.16 -0.19  \n",
       " 3 -0.12 -0.18 -0.200000 -0.350000 -0.17 -0.10 -0.20  \n",
       " 4 -0.31 -0.29 -0.270000 -0.110000 -0.37 -0.32 -0.29  )"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the data now has the correct structure\n",
    "df.info(), df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Exploratory Data Analysis (EDA): \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive Statistics:\n",
      "            Year         Jan         Feb         Mar         Apr         May  \\\n",
      "count      145.0  145.000000  145.000000  145.000000  145.000000  145.000000   \n",
      "mean      1952.0    0.068690    0.077172    0.094828    0.068690    0.057862   \n",
      "std    42.001984    0.434603    0.441759    0.446745    0.408954    0.389138   \n",
      "min       1880.0   -0.810000   -0.630000   -0.630000   -0.600000   -0.550000   \n",
      "25%       1916.0   -0.250000   -0.240000   -0.230000   -0.250000   -0.240000   \n",
      "50%       1952.0   -0.010000   -0.040000    0.010000   -0.030000   -0.040000   \n",
      "75%       1988.0    0.320000    0.390000    0.320000    0.290000    0.280000   \n",
      "max       2024.0    1.240000    1.440000    1.390000    1.310000    1.160000   \n",
      "\n",
      "              Jun         Jul         Aug         Sep         Oct         Nov  \\\n",
      "count  145.000000  145.000000  145.000000  145.000000  145.000000  145.000000   \n",
      "mean     0.045724    0.070276    0.068552    0.073793    0.099655    0.091655   \n",
      "std      0.388585    0.370742    0.387203    0.388568    0.393634    0.402775   \n",
      "min     -0.520000   -0.510000   -0.540000   -0.580000   -0.580000   -0.580000   \n",
      "25%     -0.250000   -0.190000   -0.220000   -0.200000   -0.200000   -0.180000   \n",
      "50%     -0.050000   -0.030000   -0.050000   -0.050000    0.010000    0.020000   \n",
      "75%      0.250000    0.260000    0.260000    0.250000    0.260000    0.280000   \n",
      "max      1.240000    1.200000    1.300000    1.480000    1.340000    1.420000   \n",
      "\n",
      "              Dec         J-D         D-N         DJF         MAM         JJA  \\\n",
      "count  145.000000  145.000000  145.000000  145.000000  145.000000  145.000000   \n",
      "mean     0.065310    0.073724    0.074444    0.068889    0.073793    0.062000   \n",
      "std      0.418096    0.392545    0.391063    0.417558    0.410442    0.379218   \n",
      "min     -0.820000   -0.490000   -0.490000   -0.670000   -0.580000   -0.500000   \n",
      "25%     -0.220000   -0.200000   -0.220000   -0.230000   -0.260000   -0.220000   \n",
      "50%     -0.040000   -0.030000   -0.040000   -0.030000   -0.030000   -0.040000   \n",
      "75%      0.310000    0.310000    0.290000    0.320000    0.310000    0.270000   \n",
      "max      1.350000    1.280000    1.290000    1.350000    1.290000    1.250000   \n",
      "\n",
      "              SON  \n",
      "count  145.000000  \n",
      "mean     0.088207  \n",
      "std      0.390364  \n",
      "min     -0.520000  \n",
      "25%     -0.190000  \n",
      "50%     -0.010000  \n",
      "75%      0.280000  \n",
      "max      1.410000  \n"
     ]
    }
   ],
   "source": [
    "# Display basic statistics\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify unusually high or low temperature anomalies for all columns using IQR method\n",
    "\n",
    "outliers_dict = {}\n",
    "\n",
    "for column in df.columns[1:]:  # Excluding \"Year\" column\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define lower and upper bounds for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year   SON\n",
      "135  2015  0.99\n",
      "143  2023  1.41\n",
      "144  2024  1.29\n"
     ]
    }
   ],
   "source": [
    "    # Filter outliers for each column\n",
    "outliers_dict[column] = df[(df[column] < lower_bound) | (df[column] > upper_bound)][[\"Year\", column]]\n",
    "\n",
    "# Combine all detected outliers into a single DataFrame\n",
    "outliers_combined = pd.concat(outliers_dict.values(), axis=0).drop_duplicates()\n",
    "print(outliers_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
